{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bfbda5e5",
   "metadata": {},
   "source": [
    "# Лабораторна робота №2\n",
    "\n",
    "**Тема:** Очищення даних та інженерія ознак\n",
    "\n",
    "**Мета:** Підготувати набір даних підприємства до побудови моделей машинного навчання — очистити, трансформувати та закодувати дані, сформувати повний набір якісних ознак."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bdc22bb",
   "metadata": {},
   "source": [
    "## Завдання 1\n",
    "Здійсніть підготовку даних вашого підприємства до подальшого\n",
    "моделювання використовуючи python/jupyter:\n",
    "1. Замініть відсутні значення, якщо такі присутні та обґрунтуйте вибір методу(ів)\n",
    "2. Проведіть кодування (Categorical Encoding) категоріальних ознак\n",
    "3. Опрацюйте аномальні значення\n",
    "4. Використайте підходи масштабування ознак якщо це доцільно для ваших даних"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1460c335",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74fd186c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv(\"./data/ObesityDataSet_raw_and_data_sinthetic.csv\")\n",
    "\n",
    "# Check basic info\n",
    "print(df.shape)\n",
    "print(df.info())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48640a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose which columns to iterate; change to df.columns to include everything\n",
    "cols = df.columns\n",
    "\n",
    "# optionally exclude target or ID column\n",
    "exclude = []  # e.g. ['ID', 'target']\n",
    "cols = [c for c in cols if c not in exclude]\n",
    "\n",
    "for col in cols:\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    if pd.api.types.is_numeric_dtype(df[col]):\n",
    "        # numeric: histogram + KDE\n",
    "        sns.histplot(df[col].dropna(), kde=True, bins=30)\n",
    "        plt.title(f'Histogram of {col}')\n",
    "        plt.xlabel(col)\n",
    "        plt.ylabel('Count')\n",
    "        plt.show()\n",
    "\n",
    "        # optional: show a boxplot under it\n",
    "        plt.figure(figsize=(8, 2))\n",
    "        sns.boxplot(x=df[col].dropna())\n",
    "        plt.title(f'Boxplot of {col}')\n",
    "        plt.show()\n",
    "\n",
    "    else:\n",
    "        # categorical: if too many categories, show top-k\n",
    "        vc = df[col].value_counts(dropna=False)\n",
    "        max_categories_to_plot = 20\n",
    "        if len(vc) > max_categories_to_plot:\n",
    "            vc = vc.iloc[:max_categories_to_plot]\n",
    "            note = f\"(showing top {max_categories_to_plot} categories)\"\n",
    "        else:\n",
    "            note = \"\"\n",
    "        plt.figure(figsize=(8, max(2, 0.25 * len(vc))))\n",
    "        sns.barplot(x=vc.values, y=vc.index, palette='viridis')\n",
    "        plt.title(f'Count plot of {col} {note}')\n",
    "        plt.xlabel('Count')\n",
    "        plt.ylabel(col)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0d0b3c",
   "metadata": {},
   "source": [
    "Як показано на графіках, розподіл атрибутів дуже розсіяний, і будь-який із атрибутів важко назвати *рівномірно* розподіленим. Відповідно, якщо в датасеті будуть траплятися пропущені комірки, заповнювати їх ми будемо значенням *медіани*, оскільки середнє значення атрибутів помітно зміщене.\n",
    "\n",
    "Стосовно категоріальних даних, пропущені комірки (**до** їхнього кодування) будемо замінювати значенням *моди*, тобто найбільш поширеним значенням у вибірці. Як ми побачимо за результатом коду нижче, потреби створювати нову категорію для заміни відсутніх даних не буде (а отже ми в безпеці від перенавчання моделі)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3133f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking for empty values\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Filling empty values if present\n",
    "for col in df.columns:\n",
    "    if df[col].isnull().sum() > 0:\n",
    "        if df[col].dtype == 'object':\n",
    "            # if data type is object, fill with mode\n",
    "            df[col].fillna(df[col].mode()[0], inplace=True)\n",
    "        else:\n",
    "            # if data type is numeric, fill with median\n",
    "            df[col].fillna(df[col].median(), inplace=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127ebfb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turning categorical data into numeric using Label Encoding\n",
    "label_encoders = {}\n",
    "for col in df.select_dtypes(include='object').columns:\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "    label_encoders[col] = le\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e549e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "minmax_scaler = MinMaxScaler()\n",
    "\n",
    "scaled_columns = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "df[scaled_columns] = minmax_scaler.fit_transform(df[scaled_columns])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c2ef6e",
   "metadata": {},
   "source": [
    "**Масштабування ознак**\n",
    "\n",
    "Всі числові ознаки нормалізуються за допомогою MinMaxScaler. Таким чином ми обмежили значення атрибутів до проміжку `[0, 1]`, хоч і даний метод досить чутливий до викидів. На щастя, у нашому датасеті такі відсутні, отже ми можемо використовувати його без остраху — інакше ми користувалися б StandardScaler."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c752a23",
   "metadata": {},
   "source": [
    "## Завдання 2\n",
    "Сформуйте \"Звіт про очищення даних\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e32914e2",
   "metadata": {},
   "source": [
    "### Звіт про очищення даних\n",
    "\n",
    "**1. Відсутні значення:**\n",
    "- Пропуски в даних відсутні\n",
    "- На випадок появи пропусків (при додаванні нових даних) введено застовання наступних кроків:\n",
    "    - Пропуски у числових ознаках замінено на медіану.\n",
    "    - Пропуски у категоріальних ознаках замінено на найчастіше значення (моду).\n",
    "\n",
    "**2. Кодування категоріальних ознак:**\n",
    "- Всі категоріальні ознаки закодовано числовими значеннями за допомогою LabelEncoder.\n",
    "\n",
    "**3. Обробка аномальних значень:**\n",
    "- Поверхневий огляд даних показує відсутність значущих аномалій. Задля уникнення випадкового видалення значущої інформації, цей крок був пропущений.\n",
    "\n",
    "**4. Масштабування ознак:**\n",
    "- Всі числові ознаки стандартизовано за допомогою MinMaxScaler.\n",
    "\n",
    "**Результат:**\n",
    "Дані готові до побудови моделей машинного навчання: відсутні пропуски, категорії закодовані, ознаки масштабовані."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df2f4ae9",
   "metadata": {},
   "source": [
    "## Завдання 3\n",
    "Обґрунтуйте методи інженерії даних, які були використані для підготовки даних вашого підприємства."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d85d8b1b",
   "metadata": {},
   "source": [
    "### Обґрунтування методів інженерії даних\n",
    "\n",
    "**1. Обробка пропусків:** Пропуски у даних можуть призвести до некоректної роботи моделей та втрати інформації. Для числових ознак обрана медіана, оскільки вона стійка до викидів. Для категоріальних — мода, що дозволяє зберегти найбільш поширені значення.\n",
    "\n",
    "**2. Кодування категоріальних ознак:** Більшість алгоритмів машинного навчання працюють лише з числовими даними. LabelEncoder дозволяє швидко перетворити категорії у числа, що спрощує подальше моделювання.\n",
    "\n",
    "**3. Масштабування ознак:** Стандартизація ознак забезпечує коректну роботу алгоритмів, чутливих до масштабу (наприклад, SVM, нейронні мережі). Це особливо важливо для задач класифікації ризиків, де ознаки мають різні одиниці виміру.\n",
    "\n",
    "**Висновок:** Обрані методи дозволяють підготувати якісний набір даних для побудови моделі прогнозування ризику ожиріння, що допоможе HealthGuard Insurance персоналізувати страхові тарифи та зменшити витрати на покриття хронічних захворювань."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40821b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "df.to_csv(\"./data/obesity_data_processed.csv\", index=False)\n",
    "\n",
    "start_date = pd.to_datetime('2025-01-01')\n",
    "end_date = pd.to_datetime('2025-12-31')\n",
    "\n",
    "n = len(df)\n",
    "random_dates = pd.to_datetime(\n",
    "    np.random.randint(start_date.value // 10**9, end_date.value // 10**9, n), unit='s'\n",
    ")\n",
    "df['timestamp'] = random_dates\n",
    "\n",
    "conn = sqlite3.connect('obesity_data_processed.db')\n",
    "df.to_sql(\"obesity_data_processed\", conn, if_exists='replace', index=False)\n",
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
