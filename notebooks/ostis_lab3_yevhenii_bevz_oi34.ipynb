{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bfbda5e5",
   "metadata": {},
   "source": [
    "# Лабораторна робота №3\n",
    "\n",
    "**Тема:** Тренування, оцінювання та оптимізація моделі машинного навчання.\n",
    "\n",
    "**Мета:** Підібрати відповідну модель для бізнес-проблеми, налаштувати її тренування, обрати метрики, оптимізувати гіперпараметри та оцінити важливість ознак, використовуючи реальні дані з бази підприємства."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bdc22bb",
   "metadata": {},
   "source": [
    "## Завдання 1\n",
    "Виберіть техніку моделювання, яка підходить для вирішення задачі вашого підприємства. Обґрунтуйте, чому саме класифікація, регресія або інший підхід є релевантним до вашої бізнес-проблеми."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37de725",
   "metadata": {},
   "source": [
    "Оскільки ми прагнемо передбачити *ймовірність ожиріння*, аналіз *анкетних даних* повинен давати *ймовірність* потрапляння клієнта в одну із наявних категорій ваги, яких у датасеті ми маємо сім:\n",
    "\n",
    "1. Insufficient_Weight\n",
    "2. Normal_Weight\n",
    "3. Overweight_Level_I\n",
    "4. Overweight_Level_II\n",
    "5. Obesity_Type_I\n",
    "6. Obesity_Type_II\n",
    "7. Obesity_Type_III\n",
    "\n",
    "Таким чином, наша техніка моделювання зводиться до **мультикласової класифікації**, оскільки маємо більше двох категорій."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec8c4fb",
   "metadata": {},
   "source": [
    "## Завдання 2\n",
    "Опишіть модельне припущення. У звіті до лабораторної поясніть, які припущення робить обрана модель (наприклад, лінійність, незалежність змінних, балансованість класів) і наскільки вони виконуються у ваших даних."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa33cd72",
   "metadata": {},
   "source": [
    "Згідно з результатами лабораторної роботи №2, модель буде робити наступні припущення:\n",
    "\n",
    "- у датасеті відсутні *пропущенні* значення\n",
    "- усі атрибути класів є *числовими*\n",
    "- дані **не** розподілені рівномірно\n",
    "- аномалії в датасеті *відсутні*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ef678e",
   "metadata": {},
   "source": [
    "## Завдання 3\n",
    "Оберіть 2–3 релевантні метрики для оцінки моделі. Наприклад: accuracy, F1-score, recall, precision, MAE, RMSE — залежно від типу задачі. Обґрунтуйте, чому саме ці метрики відповідають вашій меті (наприклад, у задачах виявлення шахрайства важливо мінімізувати false negatives)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33660e20",
   "metadata": {},
   "source": [
    "Для оцінки моделі можемо скористатися рядом метрик: Accuracy, Precision, Recall, F1-score (для кожного класу), Confusion Matrix, AUC-ROC (для мультикласу — one-vs-rest). Оскільки дані розподілені нерівномірно, то варто також звернути увагу на *зважені метрики* або *балансування класів* (наприклад, SMOTE).\n",
    "\n",
    "Відповідно, для нашої моделі обираємо:\n",
    "- **F1-score**: середнє між precision і recall, що важливо для мультикласових задач;\n",
    "- **AUC-ROC**: показує, наскільки добре модель відрізняє один клас від усіх інших. Для мультикласу використовується підхід *One-vs-Rest* (обчислюється AUC для кожного класу окремо, а потім береться середнє).\n",
    "- **Confusion Matrix**: показує, де модель помиляється: які класи плутає, які передбачає правильно."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb1b0b7",
   "metadata": {},
   "source": [
    "## Завдання 4\n",
    "Оберіть спосіб поділу даних на навчальні та тестові. Використовуйте класичний train_test_split або, за необхідності, TimeSeriesSplit чи StratifiedKFold. Поясніть логіку: наприклад, «оскільки дані мають часову природу — використовуємо розділення по часовій осі»."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e992cde",
   "metadata": {},
   "source": [
    "Оскільки дані не мають *часового компонента*, але класи *нерівномірні*, ми будемо використовувати **StratifiedKFold**, щоб зберегти пропорції класів у кожному фолді та уникнути перекосу в оцінці моделі."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36973867",
   "metadata": {},
   "source": [
    "## Завдання 5\n",
    "Реалізуйте тренування моделей на ваших train-даних (отриманих з БД). Результати тренування мають логуватись у таблицю predictions (source=\"train\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ffed3b18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Gender       Age    Height    Weight  family_history_with_overweight  FAVC  \\\n",
      "0     0.0  0.148936  0.320755  0.186567                             1.0   0.0   \n",
      "1     0.0  0.148936  0.132075  0.126866                             1.0   0.0   \n",
      "2     1.0  0.191489  0.660377  0.283582                             1.0   0.0   \n",
      "3     1.0  0.276596  0.660377  0.358209                             0.0   0.0   \n",
      "4     1.0  0.170213  0.622642  0.379104                             0.0   0.0   \n",
      "\n",
      "   FCVC       NCP      CAEC  SMOKE  CH2O  SCC       FAF  TUE      CALC  \\\n",
      "0   0.5  0.666667  0.666667    0.0   0.5  0.0  0.000000  0.5  1.000000   \n",
      "1   1.0  0.666667  0.666667    1.0   1.0  1.0  1.000000  0.0  0.666667   \n",
      "2   0.5  0.666667  0.666667    0.0   0.5  0.0  0.666667  0.5  0.333333   \n",
      "3   1.0  0.666667  0.666667    0.0   0.5  0.0  0.666667  0.0  0.333333   \n",
      "4   0.5  0.000000  0.666667    0.0   0.5  0.0  0.000000  0.0  0.666667   \n",
      "\n",
      "   MTRANS  NObeyesdad           timestamp  \n",
      "0    0.75    0.166667 2025-09-08 00:53:03  \n",
      "1    0.75    0.166667 2025-12-26 18:33:38  \n",
      "2    0.75    0.166667 2025-04-30 10:30:16  \n",
      "3    1.00    0.833333 2025-12-09 02:38:04  \n",
      "4    0.75    1.000000 2025-09-19 07:06:09  \n",
      "\n",
      "Розподіл класів:\n",
      " NObeyesdad\n",
      "0.333333    351\n",
      "0.666667    324\n",
      "0.500000    297\n",
      "0.833333    290\n",
      "1.000000    290\n",
      "0.166667    287\n",
      "0.000000    272\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "conn = sqlite3.connect('./db/obesity_data_processed.db')\n",
    "\n",
    "q = \"SELECT * FROM obesity_data_processed\"\n",
    "processed_data = pd.read_sql_query(q, conn)\n",
    "processed_data[\"timestamp\"] = pd.to_datetime(processed_data[\"timestamp\"])\n",
    "\n",
    "conn.close()\n",
    "\n",
    "print(processed_data.head())\n",
    "print(\"\\nРозподіл класів:\\n\", processed_data[\"NObeyesdad\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c19b4b8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Тренувальний набір: (1688, 17), Тестовий набір: (423, 17)\n",
      "\n",
      "Розподіл класів у тренувальному наборі:\n",
      " NObeyesdad\n",
      "0.333333    0.166469\n",
      "0.666667    0.153436\n",
      "0.500000    0.140403\n",
      "0.833333    0.137441\n",
      "1.000000    0.137441\n",
      "0.166667    0.135664\n",
      "0.000000    0.129147\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Розподіл класів у тестовому наборі:\n",
      " NObeyesdad\n",
      "0.333333    0.165485\n",
      "0.666667    0.153664\n",
      "0.500000    0.141844\n",
      "0.166667    0.137116\n",
      "1.000000    0.137116\n",
      "0.833333    0.137116\n",
      "0.000000    0.127660\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x = processed_data.drop(\"NObeyesdad\", axis=1)\n",
    "y = processed_data[\"NObeyesdad\"]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "  x, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Тренувальний набір: {x_train.shape}, Тестовий набір: {x_test.shape}\")\n",
    "\n",
    "print(\"\\nРозподіл класів у тренувальному наборі:\\n\", y_train.value_counts(normalize=True))\n",
    "print(\"\\nРозподіл класів у тестовому наборі:\\n\", y_test.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7d34483d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Додаємо цільову змінну до тренувального та тестового наборів\n",
    "train_data = x_train.copy()\n",
    "train_data[\"NObeyesdad\"] = y_train\n",
    "\n",
    "test_data = x_test.copy()\n",
    "test_data[\"NObeyesdad\"] = y_test\n",
    "\n",
    "train_data.to_csv(\"./data/train_data.csv\", index=False)\n",
    "test_data.to_csv(\"./data/test_data.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f5b85909",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect(\"./db/split_data.db\")\n",
    "\n",
    "train_data.to_sql(\"train_data\", conn, if_exists=\"replace\", index=False)\n",
    "\n",
    "test_data.to_sql(\"test_data\", conn, if_exists=\"replace\", index=False)\n",
    "\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b0b3fd82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Тренувальний набір:\n",
      " NObeyesdad\n",
      "0.333333    0.166469\n",
      "0.666667    0.153436\n",
      "0.500000    0.140403\n",
      "0.833333    0.137441\n",
      "1.000000    0.137441\n",
      "0.166667    0.135664\n",
      "0.000000    0.129147\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Тестовий набір:\n",
      " NObeyesdad\n",
      "0.333333    0.165485\n",
      "0.666667    0.153664\n",
      "0.500000    0.141844\n",
      "0.166667    0.137116\n",
      "1.000000    0.137116\n",
      "0.833333    0.137116\n",
      "0.000000    0.127660\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"Тренувальний набір:\\n\", y_train.value_counts(normalize=True))\n",
    "print(\"\\nТестовий набір:\\n\", y_test.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "389a2e87",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Per-column arrays must each be 1-dimensional",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[38]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     11\u001b[39m y_pred_train = model.predict(x_train)\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# Формуємо DataFrame для логування\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m log_df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtimestamp\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mdatetime\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnow\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43misoformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43my_pred_train\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msource\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtrain\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43my_pred_train\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mactual\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpredicted\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred_train\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m# Запис у базу даних obesity_data_processed.db\u001b[39;00m\n\u001b[32m     22\u001b[39m conn = sqlite3.connect(\u001b[33m\"\u001b[39m\u001b[33mobesity_data_processed.db\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\cheporte\\Desktop\\lpnu\\ostis\\venv\\Lib\\site-packages\\pandas\\core\\frame.py:782\u001b[39m, in \u001b[36mDataFrame.__init__\u001b[39m\u001b[34m(self, data, index, columns, dtype, copy)\u001b[39m\n\u001b[32m    776\u001b[39m     mgr = \u001b[38;5;28mself\u001b[39m._init_mgr(\n\u001b[32m    777\u001b[39m         data, axes={\u001b[33m\"\u001b[39m\u001b[33mindex\u001b[39m\u001b[33m\"\u001b[39m: index, \u001b[33m\"\u001b[39m\u001b[33mcolumns\u001b[39m\u001b[33m\"\u001b[39m: columns}, dtype=dtype, copy=copy\n\u001b[32m    778\u001b[39m     )\n\u001b[32m    780\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[32m    781\u001b[39m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m782\u001b[39m     mgr = \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    783\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma.MaskedArray):\n\u001b[32m    784\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mma\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m mrecords\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\cheporte\\Desktop\\lpnu\\ostis\\venv\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:503\u001b[39m, in \u001b[36mdict_to_mgr\u001b[39m\u001b[34m(data, index, columns, dtype, typ, copy)\u001b[39m\n\u001b[32m    499\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    500\u001b[39m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[32m    501\u001b[39m         arrays = [x.copy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[33m\"\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[32m--> \u001b[39m\u001b[32m503\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\cheporte\\Desktop\\lpnu\\ostis\\venv\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:114\u001b[39m, in \u001b[36marrays_to_mgr\u001b[39m\u001b[34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[39m\n\u001b[32m    111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[32m    112\u001b[39m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[32m    113\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m         index = \u001b[43m_extract_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    116\u001b[39m         index = ensure_index(index)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\cheporte\\Desktop\\lpnu\\ostis\\venv\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:664\u001b[39m, in \u001b[36m_extract_index\u001b[39m\u001b[34m(data)\u001b[39m\n\u001b[32m    662\u001b[39m         raw_lengths.append(\u001b[38;5;28mlen\u001b[39m(val))\n\u001b[32m    663\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(val, np.ndarray) \u001b[38;5;129;01mand\u001b[39;00m val.ndim > \u001b[32m1\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m664\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mPer-column arrays must each be 1-dimensional\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    666\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m indexes \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m raw_lengths:\n\u001b[32m    667\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mIf using all scalar values, you must pass an index\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mValueError\u001b[39m: Per-column arrays must each be 1-dimensional"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "model = CatBoostClassifier(verbose=0, random_state=42)\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "y_pred_train = model.predict(x_train)\n",
    "\n",
    "# Формуємо DataFrame для логування\n",
    "log_df = pd.DataFrame({\n",
    "    \"timestamp\": [datetime.now().isoformat()] * len(y_pred_train),\n",
    "    \"source\": [\"train\"] * len(y_pred_train),\n",
    "    \"actual\": y_train,\n",
    "    \"predicted\": y_pred_train\n",
    "})\n",
    "\n",
    "# Запис у базу даних obesity_data_processed.db\n",
    "conn = sqlite3.connect(\"obesity_data_processed.db\")\n",
    "log_df.to_sql(\"predictions\", conn, if_exists=\"append\", index=False)\n",
    "conn.close()\n",
    "\n",
    "print(\"✅ Результати тренування залоговано у таблицю 'predictions'.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
